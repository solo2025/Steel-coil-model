import streamlit as st
import pandas as pd
import joblib
import os
import numpy as np

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="é’¢å·æ€§èƒ½é¢„æµ‹å¹³å°",
    page_icon="ğŸ“Š",
    layout="wide"
)

# åŠ è½½CSSæ ·å¼
def local_css(file_name):
    with open(file_name) as f:
        st.markdown(f"<style>{f.read()}</style>", unsafe_allow_html=True)

# åˆå§‹åŒ–æ¨¡å‹åˆ—è¡¨
@st.cache_resource
def load_models():
    model_dir = 'models'
    models = {}
    if os.path.exists(model_dir):
        for file in os.listdir(model_dir):
            if file.endswith('.pkl'):
                model_path = os.path.join(model_dir, file)
                models[file] = model_path
    return models

# å®‰å…¨å½’ä¸€åŒ–å‡½æ•°
def safe_normalize(df):
    """å¤„ç†å¯èƒ½äº§ç”ŸNaNçš„å½’ä¸€åŒ–"""
    normalized_df = df.copy()
    for col in df.columns:
        col_min = df[col].min()
        col_max = df[col].max()
        # é¿å…é™¤ä»¥0
        if col_max != col_min:
            normalized_df[col] = (df[col] - col_min) / (col_max - col_min)
        else:
            normalized_df[col] = 0  # æ‰€æœ‰å€¼ç›¸åŒåˆ™è®¾ä¸º0
    return normalized_df

# æ•°æ®éªŒè¯å‡½æ•°
def validate_data(df, required_cols):
    """æ£€æŸ¥æ•°æ®æœ‰æ•ˆæ€§"""
    # æ£€æŸ¥ç¼ºå¤±åˆ—
    missing_cols = [col for col in required_cols if col not in df.columns]
    if missing_cols:
        raise ValueError(f"ç¼ºå°‘å¿…è¦ç‰¹å¾åˆ—ï¼š{missing_cols}")
    
    # æ£€æŸ¥æ— æ•ˆå€¼
    if df.isnull().any().any():
        raise ValueError("æ•°æ®åŒ…å«ç©ºå€¼")
    
    # æ£€æŸ¥æ— ç©·å¤§å€¼
    if np.isinf(df.values).any():
        raise ValueError("æ•°æ®åŒ…å«æ— ç©·å¤§å€¼")

# ä¸»å‡½æ•°
def main():
    st.title("ğŸ“Š é’¢å·æ€§èƒ½æœºå™¨å­¦ä¹ é¢„æµ‹å¹³å°")
    st.markdown("### ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œé¢„æµ‹")
    
    # ä¾§è¾¹æ é…ç½®
    st.sidebar.header("æ¨¡å‹é…ç½®")
    
    # åŠ è½½æ¨¡å‹åˆ—è¡¨
    models_dict = load_models()
    
    if not models_dict:
        st.error("æœªæ‰¾åˆ°ä»»ä½•æ¨¡å‹æ–‡ä»¶ï¼è¯·ç¡®è®¤outputç›®å½•ä¸‹å­˜åœ¨pklæ¨¡å‹æ–‡ä»¶")
        return
    
    # æ¨¡å‹é€‰æ‹©å™¨
    selected_model = st.sidebar.selectbox(
        "é€‰æ‹©æ¨¡å‹æ–‡ä»¶",
        options=list(models_dict.keys()),
        help="é€‰æ‹©è¦ä½¿ç”¨çš„è®­ç»ƒæ¨¡å‹"
    )
    
    # åŠ è½½é€‰ä¸­çš„æ¨¡å‹
    try:
        model = joblib.load(models_dict[selected_model])
        st.sidebar.success("æ¨¡å‹åŠ è½½æˆåŠŸ")
    except Exception as e:
        st.sidebar.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
        return
    
    # æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
    st.markdown("### ğŸ“ æ•°æ®ä¸Šä¼ ")
    uploaded_file = st.file_uploader(
        "ä¸Šä¼ CSVæµ‹è¯•æ•°æ®æ–‡ä»¶",
        type=["csv"],
        help="è¯·ä¸Šä¼ åŒ…å«ç‰¹å¾åˆ—çš„CSVæ–‡ä»¶ï¼ˆéœ€ä¸è®­ç»ƒæ•°æ®æ ¼å¼ä¸€è‡´ï¼‰"
    )
    
    if uploaded_file is not None:
        try:
            # è¯»å–æ•°æ®
            df = pd.read_csv(uploaded_file)
            
            # å®šä¹‰ç‰¹å¾åˆ—ï¼ˆæ ¹æ®å®é™…æ¨¡å‹è°ƒæ•´ï¼‰
            feature_columns = ['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 
                             'x10', 'x11', 'x12', 'x13', 'x14', 'x15', 'x16', 'x17', 
                             'x18', 'x19']
            
            # éªŒè¯æ•°æ®
            validate_data(df, feature_columns)
            
            # æå–ç‰¹å¾æ•°æ®
            X = df[feature_columns]

            # æ•°æ®é¢„è§ˆï¼ˆé™åˆ¶æ˜¾ç¤ºè¡Œæ•°ï¼‰
            st.markdown("#### æ•°æ®é¢„è§ˆï¼ˆå‰5è¡Œï¼‰")
            st.dataframe(X.head(), use_container_width=True, height=200)

            # å®‰å…¨å½’ä¸€åŒ–
            X_normalized = safe_normalize(X)

            # é¢„æµ‹æŒ‰é’®
            if st.button("ğŸ”® å¼€å§‹é¢„æµ‹", type="primary"):
                with st.spinner("æ­£åœ¨é¢„æµ‹..."):
                    # è¿›è¡Œé¢„æµ‹
                    predictions = model.predict(X_normalized)
                    
                    # åˆ›å»ºç»“æœDataFrame
                    result_df = pd.DataFrame({
                        'é¢„æµ‹ç»“æœ': predictions
                    })
                    
                    # åˆå¹¶åŸå§‹æ•°æ®å’Œé¢„æµ‹ç»“æœ
                    final_df = pd.concat([df.reset_index(drop=True), result_df], axis=1)
                    
                    # æ˜¾ç¤ºé¢„æµ‹ç»“æœï¼ˆåˆ†é¡µæ˜¾ç¤ºï¼‰
                    st.markdown("### ğŸ“Œ é¢„æµ‹ç»“æœï¼ˆå‰100è¡Œï¼‰")
                    st.dataframe(final_df.head(100), use_container_width=True)
                    
                    # æä¾›ä¸‹è½½é“¾æ¥
                    csv = final_df.to_csv(index=False)
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è½½é¢„æµ‹ç»“æœ",
                        data=csv,
                        file_name="prediction_results.csv",
                        mime="text/csv"
                    )
                    
        except Exception as e:
            st.error(f"æ•°æ®å¤„ç†é”™è¯¯: {str(e)}")
            st.exception(e)  # æ˜¾ç¤ºå®Œæ•´é”™è¯¯å †æ ˆ
    
    # æ¨¡å‹ä¿¡æ¯æ˜¾ç¤º
    st.markdown("### â„¹ï¸ æ¨¡å‹ä¿¡æ¯")
    if hasattr(model, 'get_params'):
        params = model.get_params()
        st.json(params, expanded=False)
    else:
        st.info("æ— æ³•è·å–æ¨¡å‹å‚æ•°ä¿¡æ¯")

if __name__ == "__main__":
    main()